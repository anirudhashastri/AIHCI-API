{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "import os\n",
    "import pyttsx3\n",
    "import speech_recognition as sr\n",
    "from groq import Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Groq client\n",
    "client = Groq(\n",
    "    api_key=os.environ.get(\"GROQ_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to list and choose a microphone\n",
    "def select_microphone():\n",
    "    # List available microphones\n",
    "    mics = sr.Microphone.list_microphone_names()\n",
    "    print(\"Available microphones:\")\n",
    "    for i, mic in enumerate(mics):\n",
    "        print(f\"{i}: {mic}\")\n",
    "    mic_index = int(input(\"Choose a microphone by entering the index number: \"))\n",
    "    return sr.Microphone(device_index=mic_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to use Groq API and TTS\n",
    "def ask_groq_api(query, engine):\n",
    "    # Make the chat completion request\n",
    "    # role: user or assistant (assistant is the default) \n",
    "    # content: the text of the message to be processed\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": query,\n",
    "            }\n",
    "        ],\n",
    "        # The model used is Meta-Learning Large Language Model (LLAMA): llama3-70b\n",
    "        model=\"llama3-70b-8192\",\n",
    "    )\n",
    "    \n",
    "    # Extract the generated response text\n",
    "    response_text = chat_completion.choices[0].message.content\n",
    "    print(\"Groq API Response:\", response_text)\n",
    "    \n",
    "    # Use TTS to speak the response\n",
    "    engine.say(response_text)\n",
    "    engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Main function to listen, process, and respond\n",
    "def interactive_chat(engine, recognizer):\n",
    "    print(\"Setting up microphone...\")\n",
    "    mic = select_microphone()\n",
    "    print(\"You can start speaking now.\")\n",
    "    engine.say(\"You can start speaking now.\")\n",
    "    engine.runAndWait()\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            # Use the microphone as source\n",
    "            with mic as source:\n",
    "                print(\"Listening...\")\n",
    "                engine.say(\"Listening...\")\n",
    "                engine.runAndWait()\n",
    "                recognizer.adjust_for_ambient_noise(source)\n",
    "                audio = recognizer.listen(source)\n",
    "                \n",
    "                \n",
    "            # Recognize speech using Google Speech Recognition\n",
    "            query = recognizer.recognize_google(audio)\n",
    "            print(\"You said:\", query)\n",
    "            \n",
    "            # Send the transcribed text to Groq API and respond\n",
    "            ask_groq_api(query,engine)\n",
    "\n",
    "\n",
    "        # Error handling for speech recognition\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Could not understand audio. Please try again.\")\n",
    "        except sr.RequestError as e:\n",
    "            print(\"Could not request results; check your internet connection.\")\n",
    "        \n",
    "        # Option to exit\n",
    "        if input(\"Do you want to ask another question? (yes to continue, no to exit): \").lower() != \"yes\":\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up microphone...\n",
      "Available microphones:\n",
      "0: Microsoft Sound Mapper - Input\n",
      "1: Microphone Array (Realtek High \n",
      "2: Microsoft Sound Mapper - Output\n",
      "3: Speakers (Realtek High Definiti\n",
      "4: Primary Sound Capture Driver\n",
      "5: Microphone Array (Realtek High Definition Audio(SST))\n",
      "6: Primary Sound Driver\n",
      "7: Speakers (Realtek High Definition Audio(SST))\n",
      "8: Speakers (Realtek High Definition Audio(SST))\n",
      "9: Microphone Array (Realtek High Definition Audio(SST))\n",
      "10: Headphones ()\n",
      "11: Headphones ()\n",
      "12: Headphones 1 (Realtek HD Audio 2nd output with SST)\n",
      "13: Headphones 2 (Realtek HD Audio 2nd output with SST)\n",
      "14: PC Speaker (Realtek HD Audio 2nd output with SST)\n",
      "15: Headset Microphone (Headset Microphone)\n",
      "16: Microphone Array (Realtek HD Audio Mic input)\n",
      "17: Speakers 1 (Realtek HD Audio output with SST)\n",
      "18: Speakers 2 (Realtek HD Audio output with SST)\n",
      "19: PC Speaker (Realtek HD Audio output with SST)\n",
      "20: Headset (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free%0\n",
      ";(MINIJAMBOX by Jawbone))\n",
      "21: Headset (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free%0\n",
      ";(MINIJAMBOX by Jawbone))\n",
      "22: Headphones ()\n",
      "23: Speakers ()\n",
      "24: Headphones ()\n",
      "25: Headset (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free%0\n",
      ";(JBL LIVE500BT))\n",
      "26: Headset (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free%0\n",
      ";(JBL LIVE500BT))\n",
      "27: Headphones ()\n",
      "28: Headphones ()\n",
      "29: Headset (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free%0\n",
      ";(HD 450SE))\n",
      "30: Headset (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free%0\n",
      ";(HD 450SE))\n",
      "31: Headset (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free%0\n",
      ";(JBL LIVE PRO 2 TWS))\n",
      "32: Headset (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free%0\n",
      ";(JBL LIVE PRO 2 TWS))\n",
      "33: Headset Earphone (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free%0\n",
      ";(Big bro))\n",
      "34: Headset Microphone (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free%0\n",
      ";(Big bro))\n",
      "35: Headset (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free%0\n",
      ";(WH-1000XM4))\n",
      "36: Headset (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free%0\n",
      ";(WH-1000XM4))\n",
      "37: Headset (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free%0\n",
      ";(Jabra Elite Active 75t))\n",
      "38: Headset (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free%0\n",
      ";(Jabra Elite Active 75t))\n",
      "39: Speakers ()\n",
      "You can start speaking now.\n",
      "Listening...\n",
      "You said: how are you\n",
      "Groq API Response: I'm just a language model, so I don't have emotions or feelings like humans do. However, I'm functioning properly and ready to assist you with any questions or tasks you may have! Is there anything specific you'd like to know or discuss?\n"
     ]
    }
   ],
   "source": [
    "# Initialize TTS engine\n",
    "engine = pyttsx3.init()\n",
    "# Set up recognizer \n",
    "# Recognizer class is used to recognize speech from audio source\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# Run the interactive chat\n",
    "# After each interaction, the user is prompted to ask another question\n",
    "# If the user types \"no\", the program will exit\n",
    "# If the user types \"yes\", the program will continue to listen for the next question\n",
    "# The user can also exit the program by pressing Ctrl+C\n",
    "# This prompt will come after each interaction on the top of the screen in vscode\n",
    "interactive_chat(engine, recognizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HCIAPI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
